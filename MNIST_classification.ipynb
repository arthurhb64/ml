{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSi49U-E899I"
   },
   "source": [
    "Autor: Professor Edson C. V. Júnior\n",
    "\n",
    "Linkedin: https://www.linkedin.com/in/edson-cilos-032a66162/\n",
    "\n",
    "OBS: Algumas partes de códigos foram extraídos do [notebook](https://github.com/ageron/handson-ml) do Aurélien Géron.\n",
    "\n",
    " O Aurélien conta com um excelente livro na área de ML [(Link de afiliado aqui).](https://www.amazon.com.br/gp/product/B07XGF2G87/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=B07XGF2G87&linkCode=as2&tag=edsonjr0d-20&linkId=a0ddf45ae58cc1908c6511cdca2b5c5e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbuf2o-UZL-x"
   },
   "source": [
    "## MNIST\n",
    "\n",
    "Neste pequeno notebook ilustraremos a aplicação de alguns conceitos de Machine Learning relativas ao problema de classificação de dígitos. Devido ao tamanho do dataset, não é intenção do notebook fazer otimizações de modelos, mas tão somente ilustrar alguns conceitos tais como:\n",
    "\n",
    "*   Visualização de imagens à partir de matrizes em escalas de cinza\n",
    "*   SGDClassifier (sklearn)\n",
    "*   GridSearch\n",
    "*   Tópicos em classificação multiclasse\n",
    "\n",
    "Bom aprendizado!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hHU7cjTZL-_"
   },
   "source": [
    "# Configurações iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TOFvglyZL_A"
   },
   "source": [
    "\n",
    "Inicialmente, vamos importar alguns módulos comuns e configurar o matplotlib para funcionar mais elegantemente, além de configurar um módulo para salvar figuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZGRnOQ5ZL_B"
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "\n",
    "# Para ajudar na reproducibilidade\n",
    "# Aqui a seed é 42, mas não há nada de especial nisso\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(fig_id, format='png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKM38I6yZL_C"
   },
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMVcnYnFYcmx"
   },
   "source": [
    "Vamos agora importar o [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database), que um largo conjunto de dados que contém anotações à mão de dígitos, de 0 à 9. \n",
    "\n",
    "É um dataset muito utilizado para aprendizado, assim como referência quando se pretende testar novos algoritmos de classificação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz4ZuB2AZCV2"
   },
   "source": [
    " Vamos precisar importar o conjunto de dados. O sklearn já vem com uma rotina para buscar alguns datasets públicos, como é caso do MNIST. Para isso vamos utilizar 'fetch_openml()' para buscar o nosso conjunto de dados.\n",
    "\n",
    "<font color= '#5A35B6'>**Atenção:**</font>  A função `fetch_mldata()` está obsoleta desde o Scikit-Learn 0.20. Devemos, ao invés disso, utilizar o `fetch_openml()`. Observa que seguindo as boas práticas de ML, a nova função já retorna o MNIST de forma não ordenada, enquanto que `fetch_mldata()` retorna o conjunto de dados ordenados pelo rótulo. Poderá então haver diferenças dependendo da versão que você utilizar. Recomenda-se que você atualize a sua versão do sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUuGpUJFbxnV"
   },
   "outputs": [],
   "source": [
    "#Importando dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6iYdbpycU0U"
   },
   "source": [
    "Vejamos o tipo dos dados que temos a nossa disposição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDLg5otOcJ6K",
    "outputId": "85f2ec5d-3c30-4f5f-d3ee-ed84596c619f"
   },
   "outputs": [],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhwwkcB5cbj1"
   },
   "source": [
    "Esse tipo de dados é uma espécie de container implementada no Sklearn. Os elementos devem ser acessado através de \"chaves\" que dão acesso ao conjunto de dados. Para acessar as features, usamos a chave \"data\", ao passo que para acessar os rótulos usamos \"target\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCc7FleEb-5j",
    "outputId": "d45ce066-68cb-4a5b-ce3a-89c2e1e6a69d"
   },
   "outputs": [],
   "source": [
    "mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELPnpBW_dFud"
   },
   "source": [
    "Você poderia também acessar como se fosse um atributo do objeto mnist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_havl2iIdAkg",
    "outputId": "74db98e0-25d1-491e-8d7f-5322f0e43e6f"
   },
   "outputs": [],
   "source": [
    "mnist.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOyFcyoLdLjw"
   },
   "source": [
    "Vejamos as dimensões da matriz \"mnist.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cngv8cTDZL_H",
    "outputId": "fd5a86be-15fa-4acd-8818-e65701764fad"
   },
   "outputs": [],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8LX_nlydQbu"
   },
   "source": [
    "Agora vamos instanciar as features do problemas em uma matriz X e os rótulos no vetor y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-1lTRg2ZL_I",
    "outputId": "7e611215-437d-4fbc-fbe0-84f1b2b34d5d"
   },
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyetdzuwdiSY"
   },
   "source": [
    "Temos um total de 70000 instâncias e 784 features/características. Vamos agora tentar entender melhor do que se tratam essas 784 características.\n",
    "\n",
    "Primeiramente, devemos lembrar que os nossos dados são \n",
    "<font color= '#5A35B6'>**imagens**</font>. Para ser mais preciso, as 784 representam as intesidades, na escala preto e branco, de cada pixel de uma imagem quadrada com 28px em cada dimensão. \n",
    "\n",
    "Note que 28*28 = 784.\n",
    "\n",
    "Vamos agora pegar um dígito, redimensionar em 28 por 28 pixels e visualizar essa imagem.\n",
    "\n",
    "A seguir, chamamos o \"plt\" do matplotlib, colocando como argumento três paramêmtros:\n",
    "\n",
    "- A matriz que representa a imagem;\n",
    "\n",
    "- O mapeamento de cores (color map - cmap). No nosso caso, usaremos inicialmente um esquema binário preto e branco;\n",
    "\n",
    "- Método de interpolação: originalmente a nossa imagem tem dimensões 28X28 em pixels, ao passo que o matplotlib pode dispor a imagem em outras dimensões, requerendo uma técnica \"interpolação\" para preencher pixels faltando quando redimensionamos a imagem. Para essa finalidade, recomendo usar o método a seguir usando três técnicas: 'nearest', 'gaussian' e 'lanczos'. Em cada uma delas execute o código, que vai gerar uma imagem, após isso abra a imagem em outra aba e afaste (ctrl --) e aproxime (ctrl ++) a imagem para entender esse efeito da interpolação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "9HGUPU6GZL_K",
    "outputId": "572a2b7a-43ad-4f3f-9a68-7fe85e3bc478"
   },
   "outputs": [],
   "source": [
    "some_digit = X.iloc[36000]\n",
    "some_digit_image = some_digit.values.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, \n",
    "           cmap = mpl.cm.binary,\n",
    "           interpolation= 'nearest')\n",
    "\n",
    "plt.axis(\"off\") #para desligar os eixos da imagem\n",
    "\n",
    "save_fig(\"some_digit_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZPAQHWnjwx3"
   },
   "source": [
    "Vejamos o rótulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvC9SJHFjvaZ",
    "outputId": "37910f96-be7f-4b2e-ad16-df47b735ba76"
   },
   "outputs": [],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmCsEWTrjjsX"
   },
   "source": [
    "Vamos agora definir uma função que servirá para plotar as imagens, que basicamente organiza o código que ilustramos anteriormente, podendo ser chamado várias vezes se quisermos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKQW4no6ZL_K"
   },
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.values.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOv5FuLwkAIH"
   },
   "source": [
    "Agora vamos separa o nosso conjunto de treino e teste. Observe que não precisaríamos embaralhar os dados pois eles já vieram embaralhados!\n",
    "\n",
    "Mas vamo embaralhar apenas que você não se esqueça desse detalhe muito importante.\n",
    "\n",
    "Aqui estaremos utilizando 60000 imagens para treino e 10000 para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWbFBiAoZL_O"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dAVZrvfZL_O"
   },
   "outputs": [],
   "source": [
    "#Embaralhemento \n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train.iloc[shuffle_index], y_train.iloc[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD74VS7XZL_m"
   },
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ3_Xd0b31A8"
   },
   "source": [
    "Agora vamos usar o conjunto de treinamento através de um esquema de validação cruzada para eleger o modelo mais indicado para o nosso problema. \n",
    "\n",
    "Antes disso faça um estudo sobre modelos lineares que usam Gradiente Descendente Estocástico (SGD):\n",
    "\n",
    "- Faça uma leitura sobre assunto no [**guia do usuário**](https://scikit-learn.org/stable/modules/sgd.html#sgd) do sklearn. De acordo com o guia, esses modelos lineares são bem importantes para classificação de textos e processamento natural de linguagem (NLP);\n",
    "\n",
    "- Dê uma olhada no [**SGDClassifier do sklearn**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier). Leia os parágrafos inciais da documemtanção até parte que inicia a descrição dos parâmetros da classe, preste atenção principalmente nos parâmetros: \"loss\", \"penalty\" e \"alpha\".\n",
    "\n",
    "Vamos fazer uma otimização através dos seguintes parâmetros:\n",
    "\n",
    "loss : ['hinge', 'log']\n",
    "\n",
    "alpha: [1e-4,  1e-2,  1]\n",
    "\n",
    "Pode-se incluir a penalização também, mas evitaremos muitos parâmetros pois o treinamento é demorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxMAoACmRwIo",
    "outputId": "a8b97fda-3b96-4c5e-f7a7-c9ce8d5bde30"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline #Para criar um pipeline!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('std_scaler', StandardScaler()),\n",
    "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
    "             ]) #O nosso modelo passará pelo std_scaler e depois pelo estimador\n",
    "\n",
    "#Usaremos 10 epochs, por isso max_iter = 10 \n",
    "#Cuidado, valores alto de max_iter fazem o algortirmo demorar\n",
    "#Outros valores para max_iter ou random_state, vão alterar o resultado\n",
    "\n",
    "param_grid = [{'estimator__loss' : ['hinge', 'log_loss'],\n",
    "               'estimator__alpha': [1e-4, 1e-2, 1],\n",
    "               }] #grade de parâmet\n",
    "\n",
    "#Quanto maior o verbose no GridSearch, mais detalhes sobre o processo\n",
    "#n_jobs = -1 signifca o número de cores da máquina (-1 usa todos)\n",
    "arch = GridSearchCV(pipe, param_grid, cv=5, n_jobs=2, verbose=10)\n",
    "arch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFq2z3afc_0i"
   },
   "source": [
    "Vamos agora visualizar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "20dhXNEAcZhP",
    "outputId": "527aacef-7149-4392-c6ab-a6dc9f302b5f"
   },
   "outputs": [],
   "source": [
    "results = pd.concat([pd.DataFrame(arch.cv_results_[\"params\"]),\n",
    "                     pd.DataFrame(arch.cv_results_['std_test_score'], \n",
    "                                  columns=[\"Std\"]),\n",
    "                     pd.DataFrame(arch.cv_results_[\"mean_test_score\"], \n",
    "                                  columns=[\"Score\"])],axis=1)\n",
    "\n",
    "results.sort_values(\"Score\", ascending=False) #Ordenamento decrescente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvvD-tfVaS-0"
   },
   "source": [
    "<font color= '#5A35B6'>**Observações**</font> importantes:\n",
    "\n",
    "\n",
    "\n",
    "* Fazendo uma análise preliminar, há indícios de que uma regularização l2 com alpha 0.0001 fornece as melhores respostas. Observa ainda que o modelo está indicado que está havendo subajuste (menor alpha, menos regularização), o que indica que deveríamos procurar um modelo mais complexo para a situação.\n",
    "\n",
    "*   Outro fato importante de se observar é que não estipulamos o \"score\" no gridSearch e nesse caso o score será herdado do estimador. No nosso exemplo o SGDClassifier por padrão calcula a acurácia, então o score na tabela significa acurácia. \n",
    "\n",
    "Vamos agora treinar um modelo com os melhores parametros do GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJ3H65RnvUX0",
    "outputId": "4b86b885-5970-4b07-b205-5b0fe40149f7"
   },
   "outputs": [],
   "source": [
    "model = Pipeline([('std_scaler', StandardScaler()),\n",
    "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
    "             ])\n",
    "\n",
    "model.set_params(**arch.best_params_) #Introduz no pipeline os parameos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "di-dwmsvx_Hb",
    "outputId": "a971a6e4-327d-432e-b4f8-1b69b771858e"
   },
   "outputs": [],
   "source": [
    "#Treinando o modelo\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LByZLgUJiWYg"
   },
   "source": [
    "Vamos agora pegar um elemento do conjunto de teste para dar uma pequena espiada se o modelo está funcionando. \n",
    "\n",
    "<font color= '#5A35B6'>**Cuidado**</font>: Teoricamente não se deve usar o conjunto de teste até o final do processo. Então devemos utilizar ele agora. Mas se quisermos ser bem rigorosos, no final bastaria não considerar essa única instância que faríamos esse teste preliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rniEmReNgQCH",
    "outputId": "52ca6c14-419d-4be3-db8e-5f9649255c08"
   },
   "outputs": [],
   "source": [
    "#Instanciando e treinando um digito em espcifico:\n",
    "some_digit = X_test.iloc[0]\n",
    "model.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACv01oXyyhoK",
    "outputId": "7196d5af-84c8-4621-8fdb-d3cb40c591fb"
   },
   "outputs": [],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxsO-wgEykAF"
   },
   "source": [
    "O resultado foi o esperado? \n",
    "\n",
    "O SGD é treinado em um esquema OvR, de forma que cada classe tem um estimador associado. Dessa forma, cada estimador fornece um score correspondente a uma certa classe, de forma que o algoritmo rotula a nova instância com o estimador que obteve o maior score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZys7jYGZL_n",
    "outputId": "5dcf9dc1-f70a-4c6a-fd6c-2613e6e121ff"
   },
   "outputs": [],
   "source": [
    "some_digit_scores = model.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPV7z783ZL_n",
    "outputId": "73d69401-ede8-4d5e-fe67-a0aaa3530255"
   },
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vm_tGokWZL_o",
    "outputId": "7058442b-cda8-43c6-f7a2-d624eafb606b"
   },
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yIa_JG5zT-l"
   },
   "source": [
    "Agora nós faremos uma coisa interessante: \n",
    "\n",
    "Vamos forçar o SGD a usar esquema OvO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PIBJMbkwZL_p"
   },
   "outputs": [],
   "source": [
    "#classe que implementa OvO na força\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "#Vamos aumentar o número de iterações.\n",
    "#Lembra que na técnica OvO há mais treinamentos mas pode ser interessante \n",
    "#quando o modelo sofre com a escala\n",
    "\n",
    "model = Pipeline([('std_scaler', StandardScaler()),\n",
    "                 ('estimator', SGDClassifier(max_iter = 1000, random_state=42))\n",
    "             ])\n",
    "\n",
    "model.set_params(**arch.best_params_)\n",
    "ovo_clf = OneVsOneClassifier(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I07NohmM0jLW"
   },
   "source": [
    "Façamos uma validação cruzada para verificar o desempenho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49wQQzUg0dRB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(ovo_clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgqBycS51fio",
    "outputId": "a1f7ab9f-f58e-43ea-e374-c2f559c69715"
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3J2koe521hw7",
    "outputId": "aedc7131-936e-4946-b182-7666cb908660"
   },
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC5ISJWL1yL2"
   },
   "source": [
    "Vamos treinar no conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBmoBigu0IZm",
    "outputId": "d0c40847-3f97-4189-f4eb-3d88ad5d5194"
   },
   "outputs": [],
   "source": [
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yUB8PpT00sS"
   },
   "source": [
    "Como temos 10 classes ao todo, no esquema OvO treinamos um total de  $\\displaystyle C_{10, 2} = \\frac{10!}{(10-2)! 2! } = 45$ modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrK08FtzZL_p",
    "outputId": "c44a640e-4149-4d01-a992-f0e5a03b7285"
   },
   "outputs": [],
   "source": [
    "len(ovo_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypu3G4aF3kbM"
   },
   "source": [
    "Agora vamos preparar o nosso modelo para uma avaliação final no conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCEcaJ64ZL_r"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics  import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDzbfuKlZL_s",
    "outputId": "4879cbd2-d528-4f68-fb3a-00828c407c36"
   },
   "outputs": [],
   "source": [
    "y_pred = ovo_clf.predict(X_test)\n",
    "conf_mx = confusion_matrix(y_test, y_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FaDkhi95qFt",
    "outputId": "9ec73335-6925-4471-89db-be4d4c60bbbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QG_uFcNS-Q6f"
   },
   "source": [
    "## Agora é a sua vez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwaYz6k8-U63"
   },
   "source": [
    "Agora você deve repetir o processo, mas utilizando uma etapa de pré-processamento chamando \"data augmentation\". No caso de imagens, essa técnica pode consistir de diversas metodologias, como: aumentar o número de instâncias de treinamento com rotações e translações das imagens. \n",
    "\n",
    "Nesse caso, a tua missão é treinar um novo modelo no MNIST utilizando translações no conjunto de treinamento. Fazendo isso, ensinamos o modelo a não esperar a figura centrada na imagem, podendo aumentar sua performance no teste. \n",
    "\n",
    "**Sua tarefa:**\n",
    "\n",
    "- Crie uma função  para aumentar o conjunto de **treinamento**, de forma a fazer translações nas imagens. Após isso, você deve treinar o SGDClassifier nesse conjunto de dados aumentado.\n",
    "\n",
    "- Teste o modelo no mesmo conjunto de teste que eu separei - isso é apenas um artifício didático para comparar o data augmentation, a partir do segundo teste a estimativa do erro de generalização deveria ser corrigida se quisermos obter uma estiva de performance!\n",
    "\n",
    "\n",
    "Se você estiver com dificuldades, veja a solução do exercício 2 aqui nesse [notebook](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb) do A. Géron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro importamos os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QtFpoCI-p2M"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos o conjunto de dados e separamos em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QtFpoCI-p2M"
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X = mnist.data.values.astype(np.float32).reshape(-1, 28, 28, 1)\n",
    "y = mnist.target.astype(np.int32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geramos o objeto que irá aumentar as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QtFpoCI-p2M"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentamos o conjunto de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QtFpoCI-p2M"
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QtFpoCI-p2M"
   },
   "outputs": [],
   "source": [
    "augmented_images = datagen.flow(X_train, y_train, batch_size=56000, shuffle=False)\n",
    "\n",
    "augmented_X_train, augmented_y_train = next(augmented_images)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(augmented_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntamos o conjunto de treino com o aumento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = np.concatenate((X_train, augmented_X_train), axis=0)\n",
    "y_train_combined = np.concatenate((y_train, augmented_y_train), axis=0)\n",
    "\n",
    "X_train_reshaped = X_train_combined.reshape(-1, 28*28)\n",
    "print(X_train_reshaped.shape)\n",
    "print(type(X_train_reshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos a pipeline e fazemos o Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('std_scaler', StandardScaler()),\n",
    "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
    "             ])\n",
    "\n",
    "param_grid = [{'estimator__loss' : ['hinge', 'log_loss'],\n",
    "               'estimator__alpha': [1e-4, 1e-2, 1],\n",
    "               }]\n",
    "\n",
    "arch = GridSearchCV(pipe, param_grid, cv=5, n_jobs=2, verbose=10)\n",
    "arch.fit(X_train_reshaped, y_train_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([('std_scaler', StandardScaler()),\n",
    "                 ('estimator', SGDClassifier(max_iter = 1000, random_state=42))\n",
    "             ])\n",
    "\n",
    "model.set_params(**arch.best_params_)\n",
    "model.fit(X_train_reshaped, y_train_combined)\n",
    "ovo_clf = OneVsOneClassifier(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores finais da validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(ovo_clf, X_train_reshaped, y_train_combined, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo_clf.fit(X_train_reshaped, y_train_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshaped = X_test.reshape(-1, 28*28)\n",
    "y_pred = ovo_clf.predict(X_test_reshaped)\n",
    "conf_mx = confusion_matrix(y_test, y_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KbMhJyi8ZL_z",
    "s64qshzXZL_6",
    "3_SJ_7IPZL_-"
   ],
   "name": "MNIST_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
